# 로지스틱스 회귀
## 회귀모형인 것 같지만 이진분류 모형이다.
## 데이터가 어떤 범주에 속할 확률을 구해 그 확률에 따라 이진분류해주는 모델이다.

# 분류모형에서 accurancy의 함정
## 암을 맞추는 의사가 전부 음성이라고 예측하면 accurancy는 엄청 높게 나온다.
## 하지만 그런의사를 잘맞춘다고 보기엔 문제가 있다. 그래서 아래와 같은 지표들도 같이 봐주어야 한다.

# precision(양성예측정확도), recall
from sklearn.metrics import precision_score, recall_score

# precision - 양성으로 예측한 거 중 진짜 양성인 것 비율
## tp / tp + fp

# recall(실제트루중맞춘거) = sensitive
## 예 ) 실제 맑은 날 중 모델이 맑다고 예측한 비율
## tp / tp + fn

# f1 score, precision과 recall 의 조화평균입니다.
from sklearn.metrics import f1_score


# 산술, 기하, 조화평균에 대해서
## 산술평균은 우리가 알고 있는 그 평균의 개념이다.
## 기하평균은 변화율에 대한 평균, 2019년에 5%증가 2020년에 10% 증가한 gdp가 있다. 1년평균 증가율은? 이런문제를 풀때 사용한다.
### 답은 루트50
## 조화평균은 갈때 10m/s 올때 20m/s로 이동하였다. 평균 속력은? 이런 문제를 풀 때 사용한다.

# f1score 왜 조화평균을 사용할까요?
## recall = 1이고, precision이 0.01 이면 모델에 문제가 있음에도 산술평균하면 0.5정도로 괜찮게나온다.
## 그런데 조화평균해주면 0.019로 문제가 있는 모델임을 파악할 수 있게된다.

# 비용함수란?
## 경제학에서 비용함수 개념과 매우 유사하다.
## 어떤 점에서 평균비용과 한계비용이 최소가 되는지 그래프가 그려진다. 2차함수 꼴로.
## 머신러닝에서도 이렇게 오차(비용)가 비용함수처럼 어떤 점에서 최소가 되어질 것이다. 그것을 찾아서 그때 까지 학습시키면 오차가
## 최소가 되어 가장 효과적인 학습을 시킬 수 있게된다.

# 비용함수에 대한 규제
## 비용함수에 규제식을 추가하는 것으로 이해하자. 보통 오버피팅이나 언더피팅을 완화하기 위해 규제한다.
## 규제를 많이하면 훈련데이터에 덜 적합한 그래프가 그려져 과대적합을 방지할 수 있다.
## 하지만 규제를 많이하면 과소적합이 발생할 수도 있으므로 데이터셋과 모델에 적합한 규제를 해주어야 한다.

# L1 L2 규제
## L1은 가중치의 절대값을 더하는것 L2는 가중치의 제곱을 더하는 것.
## 데이터가 많이 부족할때는 규제를 많이 주는것이 일반화하기에 좋다.
# 
# 알파값에 따른 coef_ 차이?
## coef란 w이다. w는 가중치 알파값을 다르게 해줌으로써 가중치가 달라진다.
## 알파값은 규제를 얼마나 해줄것인가의 값이다.

# 릿지모델
#   릿지모델은 정규화의 컨셉을 도입한 것이다(?)
#   L2 규제를 적용한 것
#   0에 가까운 피처일 수록 더욱더 0에 가깝게 만들어줘서 과대적합을 방지해준다.

# 엘라스틱넷
# 릿지와 라쏘모델을 적정한 비율로 하이브리드하여 규젠

# standardization, normalization, minmaxscaler, robustscaler(아웃라이어가 있을 때)

# 피처간의 스케일 차이가 많이 나게 되면, 비교적 작은 스케일을 가지는 피처는 중요도가 떨어지게 된다.
# 그래서 스케일러를 해주어야 한다. 데이터가 동일한 정도의 스케일로 반영되게 해주는 것을 normalization의 목표이다.

# standardization(표준화)를 해주면 데이터를 0을 중심으로 양쪽으로 분포시킬 수 있다.(데이터를 정규분포화)
# 회귀보다 분류에 유리합니다.
# 확률계산 편함. 

# robustscaler는 평균과 표준편차 대신에 중간값과 사분위값을 사용합니다.
# 따라서 아웃라이어에 과대 반응하지 않게 됩니다.

#minmaxscaler는 모든 값을 0~1사이에 위치시킵니다.
# 분류보다 회귀에 유리합니다.

#pipeline
#scaling은 훈련데이터와 테스트데이터를 각각 따로 해주어야한다. 이러한 과정을 단순화하는 도구이다. 그리고 fit까지 진행해준다.

#polynomial features
#비선형 데이터를 학습시키고 싶을 때, 각 피처의 거듭제곱을 새로운파처로 추가하고 이 추가된 피처를 포함해서 데이터를 학습시키는 것.
#이러한 기법을 다항회귀(polynomial regression)

